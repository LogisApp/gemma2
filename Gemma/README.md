# Welcome to the Gemma Cookbook
This is a collection of guides and examples for [Google Gemma](https://ai.google.dev/gemma/).

## Get started with the Gemma models 
Gemma is a family of lightweight, state-of-the art open models built from the same research and technology used to create the Gemini models. The Gemma model family includes:
* [base Gemma](https://ai.google.dev/gemma/docs/model_card)
* [CodeGemma](https://ai.google.dev/gemma/docs/codegemma)
* [PaliGemma](https://ai.google.dev/gemma/docs/paligemma)
* [RecurrentGemma](https://ai.google.dev/gemma/docs/recurrentgemma)

You can find the Gemma models on GitHub, Hugging Face models, Kaggle, Google Cloud Vertex AI Model Garden, and [ai.nvidia.com](ai.nvidia.com).

## Table of contents

| Name                                             | Description                                                                                                                                              |
| ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Gemma**                                        |
| Gemma_Basics_with_HF.ipynb                       | Load, run, finetune and deploy Gemma using [Hugging Face](https://huggingface.co/).                                                                      |
| Guess_the_word.ipynb                             | Play a word guessing game with Gemma using Keras.                                                                                                        |
| Game_Design_Brainstorming.ipynb                  | Use Gemma to brainstorm ideas during game design using Keras.                                                                                            |
| Translator_of_Old_Korean_Literature.ipynb        | Use Gemma to translate old Korean literature using Keras.                                                                                                |
| Run_with_Ollama.ipynb                            | Run Gemma models using [Ollama](https://www.ollama.com/).                                                                                                |
| Deploy_with_vLLM.ipynb                           | Deploy a Gemma model using [vLLM](https://github.com/vllm-project/vllm).                                                                                 |
| RAG_with_ChromaDB.ipynb                          | Build a Retrieval Augmented Generation (RAG) system with Gemma using [ChromaDB](https://www.trychroma.com/) and [Hugging Face](https://huggingface.co/). |
| Minimal_RAG.ipynb                                | Minimal example of building a RAG system with Gemma using [Google UniSim](https://github.com/google/unisim) and [Hugging Face](https://huggingface.co/). |
| Integrate_with_Mesop.ipynb                       | Integrate Gemma with [Google Mesop](https://google.github.io/mesop/).                                                                                    |
| Integrate_with_OneTwo.ipynb                      | Integrate Gemma with [Google OneTwo](https://github.com/google-deepmind/onetwo).                                                                         |
| Finetune_with_Axolotl.ipynb                      | Finetune Gemma using [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl).                                                                     |
| Finetune_with_XTuner.ipynb                       | Finetune Gemma using [XTuner](https://github.com/InternLM/xtuner).                                                                                       |
| Finetune_with_LLaMA_Factory.ipynb                | Finetune Gemma using [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory).                                                                          |
