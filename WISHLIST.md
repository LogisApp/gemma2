A wish list of cookbooks showcasing:

* Inference
  * Integration with [Google GenKit](https://firebase.google.com/products/genkit)
  * HF local-gemma demo
  * Gemma+Gemini with [routerLLM](https://github.com/lm-sys/RouteLLM)
  * [SGLang](https://github.com/sgl-project/sglang) integration

* Fine-tuning
  * Fine-tuning Gemma for function calling
  * Fine-tuning Gemma and/or CodeGemma for multi-turn, agentic workloads.

* Continued Pretraining
  * Continue to pretrain Gemma on TPU
 
* Tool Use (Function Calling)
  * tool use overview
  * tool choice
     
* Responsible AI
  * Use [LLM Comparator](https://github.com/pair-code/llm-comparator) to compare Gemma with another LLM (i.e., Llama)
 
